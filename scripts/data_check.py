#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ•°æ®å­—æ®µå…¨é¢æ’æŸ¥è„šæœ¬

æ£€æŸ¥æ‰€æœ‰å‚å•†çš„æ‰€æœ‰å­—æ®µæ•°æ®å®Œæ•´æ€§å’Œæœ‰æ•ˆæ€§
"""

import os
import sys
import re
import sqlite3
import argparse
from datetime import datetime
from collections import defaultdict
from tabulate import tabulate

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = os.path.abspath(os.path.dirname(os.path.dirname(__file__)))
sys.path.insert(0, PROJECT_ROOT)

from src.storage.database import UpdateDataLayer

# æ•°æ®åº“è·¯å¾„
DB_PATH = os.path.join(PROJECT_ROOT, 'data', 'sqlite', 'updates.db')

# æ‰€æœ‰å‚å•†
VENDORS = ['aws', 'azure', 'gcp', 'huawei', 'tencentcloud', 'volcengine']

# å¿…å¡«å­—æ®µ
REQUIRED_FIELDS = ['update_id', 'vendor', 'source_channel', 'source_url', 'title', 'publish_date']

# æ‰€æœ‰å­—æ®µ
ALL_FIELDS = [
    'update_id', 'vendor', 'source_channel', 'update_type', 'source_url', 'source_identifier',
    'title', 'title_translated', 'description', 'content', 'content_summary',
    'publish_date', 'crawl_time', 'product_name', 'product_category', 'product_subcategory', 'priority', 'tags',
    'raw_filepath', 'analysis_filepath', 'file_hash', 'metadata_json'
]

# æ—¥æœŸæ ¼å¼æ­£åˆ™
DATE_PATTERN = re.compile(r'^\d{4}-\d{2}-\d{2}')
URL_PATTERN = re.compile(r'^https?://')


class DataChecker:
    """æ•°æ®æ£€æŸ¥å™¨"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.issues = defaultdict(list)
        self.stats = {}
    
    def connect(self):
        """è¿æ¥æ•°æ®åº“"""
        if not os.path.exists(self.db_path):
            print(f"âŒ æ•°æ®åº“ä¸å­˜åœ¨: {self.db_path}")
            sys.exit(1)
        return sqlite3.connect(self.db_path)
    
    def run_all_checks(self):
        """è¿è¡Œæ‰€æœ‰æ£€æŸ¥"""
        print("=" * 60)
        print("ğŸ“Š æ•°æ®å­—æ®µå…¨é¢æ’æŸ¥æŠ¥å‘Š")
        print("=" * 60)
        print(f"æ•°æ®åº“: {self.db_path}")
        print(f"æ£€æŸ¥æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print()
        
        # 1. åŸºç¡€ç»Ÿè®¡
        self.check_basic_stats()
        
        # 2. å„å‚å•†ç»Ÿè®¡
        self.check_vendor_stats()
        
        # 3. å­—æ®µå®Œæ•´åº¦
        self.check_field_completeness()
        
        # 4. å¿…å¡«å­—æ®µæ£€æŸ¥
        self.check_required_fields()
        
        # 5. æ—¥æœŸæ ¼å¼æ£€æŸ¥
        self.check_date_format()
        
        # 6. URLæ ¼å¼æ£€æŸ¥
        self.check_url_format()
        
        # 7. é‡å¤æ•°æ®æ£€æŸ¥
        self.check_duplicates()
        
        # 8. å¼‚å¸¸å€¼æ£€æŸ¥
        self.check_anomalies()
        
        # 9. AI åˆ†æè´¨é‡æ ¡éªŒ
        self.check_ai_quality()
        
        # 10. è¾“å‡ºé—®é¢˜æ±‡æ€»
        self.print_issues_summary()
    
    def check_basic_stats(self):
        """åŸºç¡€ç»Ÿè®¡"""
        print("ğŸ“ˆ 1. åŸºç¡€ç»Ÿè®¡")
        print("-" * 40)
        
        conn = self.connect()
        cursor = conn.cursor()
        
        cursor.execute("SELECT COUNT(*) FROM updates")
        total = cursor.fetchone()[0]
        
        cursor.execute("SELECT MIN(publish_date), MAX(publish_date) FROM updates WHERE publish_date IS NOT NULL AND publish_date != ''")
        date_range = cursor.fetchone()
        
        cursor.execute("SELECT MIN(crawl_time), MAX(crawl_time) FROM updates WHERE crawl_time IS NOT NULL")
        crawl_range = cursor.fetchone()
        
        # æ•°æ®åº“æ–‡ä»¶å¤§å°
        db_size = os.path.getsize(self.db_path) / 1024 / 1024
        
        print(f"  æ€»è®°å½•æ•°: {total}")
        print(f"  å‘å¸ƒæ—¥æœŸèŒƒå›´: {date_range[0]} ~ {date_range[1]}")
        print(f"  çˆ¬å–æ—¶é—´èŒƒå›´: {crawl_range[0][:10] if crawl_range[0] else 'N/A'} ~ {crawl_range[1][:10] if crawl_range[1] else 'N/A'}")
        print(f"  æ•°æ®åº“å¤§å°: {db_size:.2f} MB")
        print()
        
        conn.close()
    
    def check_vendor_stats(self):
        """å„å‚å•†ç»Ÿè®¡"""
        print("ğŸ¢ 2. å„å‚å•†æ•°æ®ç»Ÿè®¡")
        print("-" * 40)
        
        conn = self.connect()
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT vendor, source_channel, COUNT(*) as count 
            FROM updates 
            GROUP BY vendor, source_channel 
            ORDER BY vendor, source_channel
        """)
        
        vendor_data = defaultdict(dict)
        for row in cursor.fetchall():
            vendor, channel, count = row
            vendor_data[vendor][channel] = count
        
        # æ„å»ºè¡¨æ ¼
        table_data = []
        for vendor in VENDORS:
            if vendor in vendor_data:
                channels = vendor_data[vendor]
                total = sum(channels.values())
                channel_str = ', '.join([f"{k}:{v}" for k, v in channels.items()])
                table_data.append([vendor, total, channel_str])
            else:
                table_data.append([vendor, 0, "æ— æ•°æ®"])
                self.issues['missing_vendor'].append(vendor)
        
        print(tabulate(table_data, headers=['å‚å•†', 'æ€»æ•°', 'æ¸ é“åˆ†å¸ƒ'], tablefmt='simple'))
        print()
        
        conn.close()
    
    def check_field_completeness(self):
        """å­—æ®µå®Œæ•´åº¦æ£€æŸ¥"""
        print("ğŸ“‹ 3. å­—æ®µå®Œæ•´åº¦")
        print("-" * 40)
        
        conn = self.connect()
        cursor = conn.cursor()
        
        cursor.execute("SELECT COUNT(*) FROM updates")
        total = cursor.fetchone()[0]
        
        if total == 0:
            print("  æ— æ•°æ®")
            conn.close()
            return
        
        table_data = []
        for field in ALL_FIELDS:
            cursor.execute(f"""
                SELECT COUNT(*) FROM updates 
                WHERE {field} IS NOT NULL AND {field} != ''
            """)
            filled = cursor.fetchone()[0]
            rate = (filled / total) * 100
            status = "âœ“" if rate > 90 else ("âš " if rate > 50 else "âœ—")
            table_data.append([field, filled, f"{rate:.1f}%", status])
            
            if rate < 50 and field in REQUIRED_FIELDS:
                self.issues['low_completeness'].append(f"{field}: {rate:.1f}%")
        
        print(tabulate(table_data, headers=['å­—æ®µ', 'å·²å¡«å……', 'å®Œæ•´ç‡', 'çŠ¶æ€'], tablefmt='simple'))
        print()
        
        conn.close()
    
    def check_required_fields(self):
        """å¿…å¡«å­—æ®µæ£€æŸ¥"""
        print("âš ï¸  4. å¿…å¡«å­—æ®µç©ºå€¼æ£€æŸ¥")
        print("-" * 40)
        
        conn = self.connect()
        cursor = conn.cursor()
        
        has_issue = False
        for field in REQUIRED_FIELDS:
            # æŸ¥è¯¢ç©ºå€¼è®°å½•çš„å…·ä½“ä¿¡æ¯
            cursor.execute(f"""
                SELECT update_id, vendor, title, source_url FROM updates 
                WHERE {field} IS NULL OR {field} = ''
                LIMIT 10
            """)
            records = cursor.fetchall()
            
            if records:
                has_issue = True
                # ç»Ÿè®¡æ€»æ•°
                cursor.execute(f"""
                    SELECT vendor, COUNT(*) as count FROM updates 
                    WHERE {field} IS NULL OR {field} = ''
                    GROUP BY vendor
                """)
                for vendor, count in cursor.fetchall():
                    print(f"  âŒ {vendor}: {field} å­—æ®µä¸ºç©º ({count} æ¡)")
                    self.issues['empty_required'].append(f"{vendor}.{field}: {count}æ¡")
                
                # è¾“å‡ºå…·ä½“è®°å½•
                for update_id, vendor, title, source_url in records:
                    title_short = (title[:50] + '...') if title and len(title) > 50 else (title or 'N/A')
                    print(f"     â”” [{vendor}] {update_id}")
                    print(f"       æ ‡é¢˜: {title_short}")
                    print(f"       é“¾æ¥: {source_url or 'N/A'}")
        
        if not has_issue:
            print("  âœ“ æ‰€æœ‰å¿…å¡«å­—æ®µå®Œæ•´")
        print()
        
        conn.close()
    
    def check_date_format(self):
        """æ—¥æœŸæ ¼å¼æ£€æŸ¥"""
        print("ğŸ“… 5. æ—¥æœŸæ ¼å¼æ£€æŸ¥")
        print("-" * 40)
        
        conn = self.connect()
        cursor = conn.cursor()
        
        # æ£€æŸ¥ publish_date
        cursor.execute("""
            SELECT vendor, publish_date, COUNT(*) as count FROM updates 
            WHERE publish_date IS NOT NULL AND publish_date != ''
            GROUP BY vendor, publish_date
        """)
        
        invalid_dates = defaultdict(list)
        for vendor, date_str, count in cursor.fetchall():
            if not DATE_PATTERN.match(str(date_str)):
                invalid_dates[vendor].append((date_str, count))
        
        if invalid_dates:
            for vendor, dates in invalid_dates.items():
                for date_str, count in dates[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                    print(f"  âŒ {vendor}: æ— æ•ˆæ—¥æœŸæ ¼å¼ '{date_str}' ({count}æ¡)")
                    self.issues['invalid_date'].append(f"{vendor}: {date_str}")
                if len(dates) > 3:
                    print(f"      ... è¿˜æœ‰ {len(dates) - 3} ç§æ ¼å¼é—®é¢˜")
        else:
            print("  âœ“ æ‰€æœ‰æ—¥æœŸæ ¼å¼æ­£ç¡®")
        print()
        
        conn.close()
    
    def check_url_format(self):
        """URLæ ¼å¼æ£€æŸ¥"""
        print("ğŸ”— 6. URLæ ¼å¼æ£€æŸ¥")
        print("-" * 40)
        
        conn = self.connect()
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT update_id, vendor, title, source_url FROM updates 
            WHERE source_url IS NOT NULL AND source_url != ''
        """)
        
        invalid_records = []  # (update_id, vendor, title, url)
        for update_id, vendor, title, url in cursor.fetchall():
            if not URL_PATTERN.match(str(url)):
                invalid_records.append((update_id, vendor, title, url))
        
        if invalid_records:
            # æŒ‰å‚å•†ç»Ÿè®¡
            vendor_counts = defaultdict(int)
            for _, vendor, _, _ in invalid_records:
                vendor_counts[vendor] += 1
            
            for vendor, count in vendor_counts.items():
                print(f"  âŒ {vendor}: {count} æ¡æ— æ•ˆURL")
                self.issues['invalid_url'].append(f"{vendor}: {count}æ¡")
            
            # è¾“å‡ºå…·ä½“è®°å½•ï¼ˆæœ€å¤š10æ¡ï¼‰
            for update_id, vendor, title, url in invalid_records[:10]:
                title_short = (title[:50] + '...') if title and len(title) > 50 else (title or 'N/A')
                print(f"     â”” [{vendor}] {update_id}")
                print(f"       æ ‡é¢˜: {title_short}")
                print(f"       URL: {url or 'N/A'}")
            
            if len(invalid_records) > 10:
                print(f"     ... è¿˜æœ‰ {len(invalid_records) - 10} æ¡")
        else:
            print("  âœ“ æ‰€æœ‰URLæ ¼å¼æ­£ç¡®")
        print()
        
        conn.close()
    
    def check_duplicates(self):
        """é‡å¤æ•°æ®æ£€æŸ¥"""
        print("ğŸ”„ 7. é‡å¤æ•°æ®æ£€æŸ¥")
        print("-" * 40)
        
        conn = self.connect()
        cursor = conn.cursor()
        
        # æ£€æŸ¥ source_url + source_identifier é‡å¤
        cursor.execute("""
            SELECT vendor, source_url, source_identifier, COUNT(*) as count 
            FROM updates 
            GROUP BY source_url, source_identifier 
            HAVING count > 1
        """)
        
        duplicates = cursor.fetchall()
        if duplicates:
            dup_by_vendor = defaultdict(int)
            for vendor, url, identifier, count in duplicates:
                dup_by_vendor[vendor] += count - 1
            
            for vendor, count in dup_by_vendor.items():
                print(f"  âš ï¸ {vendor}: {count} æ¡é‡å¤è®°å½•")
                self.issues['duplicates'].append(f"{vendor}: {count}æ¡")
        else:
            print("  âœ“ æ— é‡å¤æ•°æ®")
        print()
        
        conn.close()
    
    def check_anomalies(self):
        """å¼‚å¸¸å€¼æ£€æŸ¥"""
        print("ğŸ” 8. å¼‚å¸¸å€¼æ£€æŸ¥")
        print("-" * 40)
        
        conn = self.connect()
        cursor = conn.cursor()
        
        anomalies = []
        
        # æ£€æŸ¥æœªæ¥æ—¥æœŸ
        today = datetime.now().strftime('%Y-%m-%d')
        cursor.execute(f"""
            SELECT update_id, vendor, title, publish_date FROM updates 
            WHERE publish_date > '{today}'
            LIMIT 10
        """)
        future_records = cursor.fetchall()
        if future_records:
            cursor.execute(f"""
                SELECT vendor, COUNT(*) FROM updates 
                WHERE publish_date > '{today}'
                GROUP BY vendor
            """)
            for vendor, count in cursor.fetchall():
                anomalies.append(f"{vendor}: {count}æ¡æœªæ¥æ—¥æœŸ")
                self.issues['anomalies'].append(f"{vendor}: æœªæ¥æ—¥æœŸ{count}æ¡")
            # è¾“å‡ºå…·ä½“è®°å½•
            for update_id, vendor, title, pub_date in future_records:
                title_short = (title[:50] + '...') if title and len(title) > 50 else (title or 'N/A')
                print(f"     â”” [{vendor}] {update_id}")
                print(f"       æ—¥æœŸ: {pub_date} | æ ‡é¢˜: {title_short}")
        
        # æ£€æŸ¥è¿‡çŸ­æ ‡é¢˜ (å°‘äº5ä¸ªå­—ç¬¦) - ä»…ä¿¡æ¯å±•ç¤ºï¼Œä¸ä½œä¸ºå‘Šè­¦
        cursor.execute("""
            SELECT vendor, COUNT(*) FROM updates 
            WHERE LENGTH(title) < 2
            GROUP BY vendor
        """)
        short_title_vendors = []
        for vendor, count in cursor.fetchall():
            if count > 0:
                short_title_vendors.append((vendor, count))
        
        # æ£€æŸ¥ç©ºå†…å®¹
        cursor.execute("""
            SELECT update_id, vendor, title FROM updates 
            WHERE (content IS NULL OR content = '') AND (description IS NULL OR description = '')
            LIMIT 10
        """)
        empty_content_records = cursor.fetchall()
        if empty_content_records:
            cursor.execute("""
                SELECT vendor, COUNT(*) FROM updates 
                WHERE (content IS NULL OR content = '') AND (description IS NULL OR description = '')
                GROUP BY vendor
            """)
            for vendor, count in cursor.fetchall():
                if count > 0:
                    anomalies.append(f"{vendor}: {count}æ¡æ— å†…å®¹å’Œæè¿°")
            # è¾“å‡ºå…·ä½“è®°å½•
            for update_id, vendor, title in empty_content_records:
                title_short = (title[:50] + '...') if title and len(title) > 50 else (title or 'N/A')
                print(f"     â”” [{vendor}] {update_id}")
                print(f"       æ ‡é¢˜: {title_short}")
        
        # æ£€æŸ¥æ— æ•ˆçš„ vendor å€¼
        cursor.execute(f"""
            SELECT DISTINCT vendor FROM updates 
            WHERE vendor NOT IN ({','.join(['?' for _ in VENDORS])})
        """, VENDORS)
        invalid_vendors = [row[0] for row in cursor.fetchall()]
        if invalid_vendors:
            anomalies.append(f"æœªçŸ¥å‚å•†: {', '.join(invalid_vendors)}")
            self.issues['anomalies'].append(f"æœªçŸ¥å‚å•†: {invalid_vendors}")
        
        if anomalies:
            for a in anomalies:
                print(f"  âš ï¸ {a}")
        else:
            print("  âœ“ æœªå‘ç°å¼‚å¸¸å€¼")
        print()
        
        # æ‰“å°è¿‡çŸ­æ ‡é¢˜è¯¦æƒ…ï¼ˆä»…ä¿¡æ¯å±•ç¤ºï¼‰
        if short_title_vendors:
            self.print_short_titles(conn, short_title_vendors)
        
        conn.close()
    
    def check_ai_quality(self):
        """
AI åˆ†æè´¨é‡æ ¡éªŒ
        
        æ ¡éªŒè§„åˆ™ï¼š
        1. ç¿»è¯‘æ ‡é¢˜ä¸å«ä¸­æ–‡
        2. æ‘˜è¦ä¸ºç©º
        3. update_type æ— æ•ˆ
        4. å¿…å¡«å­—æ®µç¼ºå¤±
        """
        print("ğŸ¤– 9. AI åˆ†æè´¨é‡æ ¡éªŒ")
        print("-" * 40)
        
        conn = self.connect()
        cursor = conn.cursor()
        
        # ç»Ÿè®¡å·²åˆ†ææ•°æ®
        cursor.execute("""
            SELECT COUNT(*) FROM updates 
            WHERE title_translated IS NOT NULL
        """)
        total_analyzed = cursor.fetchone()[0]
        
        if total_analyzed == 0:
            print("  æ— å·²åˆ†ææ•°æ®")
            print()
            conn.close()
            return
        
        print(f"  å·²åˆ†æè®°å½•æ•°: {total_analyzed}")
        print()
        
        quality_issues = []
        
        # 1. æ£€æŸ¥ç¿»è¯‘æ ‡é¢˜ä¸å«ä¸­æ–‡
        cursor.execute("""
            SELECT vendor, COUNT(*) FROM updates 
            WHERE title_translated IS NOT NULL
            GROUP BY vendor
        """)
        vendor_analyzed = {vendor: count for vendor, count in cursor.fetchall()}
        
        no_chinese_records = []
        for vendor, analyzed_count in vendor_analyzed.items():
            # ä½¿ç”¨ Python æ­£åˆ™æ£€æŸ¥ä¸­æ–‡
            cursor.execute("""
                SELECT update_id, title, title_translated, publish_date, source_url FROM updates 
                WHERE vendor = ? AND title_translated IS NOT NULL
            """, (vendor,))
            
            for update_id, title, title_translated, date, url in cursor.fetchall():
                if not re.search(r'[ä¸€-é¿¿]', title_translated or ''):
                    no_chinese_records.append({
                        'vendor': vendor,
                        'update_id': update_id,
                        'title': title,
                        'title_translated': title_translated,
                        'date': date,
                        'url': url
                    })
        
        if no_chinese_records:
            for record in no_chinese_records:
                quality_issues.append(f"{record['vendor']}: ç¿»è¯‘æ ‡é¢˜ä¸å«ä¸­æ–‡")
                print(f"\n  âŒ {record['vendor']}: ç¿»è¯‘æ ‡é¢˜ä¸å«ä¸­æ–‡")
                print(f"     ID: {record['update_id']}")
                print(f"     æ—¥æœŸ: {record['date']}")
                print(f"     åŸæ ‡é¢˜: {record['title'][:80]}")
                print(f"     ç¿»è¯‘å: {record['title_translated'][:80]}")
                print(f"     URL: {record['url']}")
        
        # 2. æ£€æŸ¥æ‘˜è¦ä¸ºç©º
        cursor.execute("""
            SELECT vendor, update_id, title, publish_date FROM updates 
            WHERE title_translated IS NOT NULL 
            AND (content_summary IS NULL OR content_summary = '')
        """)
        empty_summary_records = cursor.fetchall()
        
        if empty_summary_records:
            for vendor, update_id, title, date in empty_summary_records:
                quality_issues.append(f"{vendor}: æ‘˜è¦ä¸ºç©º")
                print(f"\n  âŒ {vendor}: æ‘˜è¦ä¸ºç©º")
                print(f"     ID: {update_id}")
                print(f"     æ—¥æœŸ: {date}")
                print(f"     æ ‡é¢˜: {title[:80]}")
        
        # 3. æ£€æŸ¥ update_type æ— æ•ˆ
        valid_types = [
            'new_product', 'new_feature', 'enhancement', 'deprecation', 
            'pricing', 'region', 'security', 'fix', 'performance', 
            'compliance', 'integration', 'other'
        ]
        placeholders = ','.join(['?' for _ in valid_types])
        cursor.execute(f"""
            SELECT vendor, update_id, title, update_type, publish_date FROM updates 
            WHERE title_translated IS NOT NULL 
            AND (update_type IS NULL OR update_type = '' OR update_type NOT IN ({placeholders}))
        """, valid_types)
        
        invalid_type_records = cursor.fetchall()
        if invalid_type_records:
            for vendor, update_id, title, update_type, date in invalid_type_records:
                quality_issues.append(f"{vendor}: update_typeæ— æ•ˆ")
                print(f"\n  âŒ {vendor}: update_typeæ— æ•ˆ")
                print(f"     ID: {update_id}")
                print(f"     æ—¥æœŸ: {date}")
                print(f"     æ ‡é¢˜: {title[:80]}")
                print(f"     å½“å‰å€¼: '{update_type}'")
        
        # 4. æ£€æŸ¥å¿…å¡«å­—æ®µç¼ºå¤±ï¼ˆå·²åˆ†æä½†å­—æ®µä¸ºç©ºï¼‰
        ai_required_fields = ['title_translated', 'content_summary', 'update_type']
        for field in ai_required_fields:
            cursor.execute(f"""
                SELECT vendor, COUNT(*) FROM updates 
                WHERE title_translated IS NOT NULL 
                AND ({field} IS NULL OR {field} = '')
                GROUP BY vendor
            """)
            for vendor, count in cursor.fetchall():
                if count > 0 and field != 'title_translated':  # title_translated å·²åœ¨ä¸Šé¢æ£€æŸ¥
                    quality_issues.append(f"{vendor}: {count}æ¡{field}ä¸ºç©º")
        
        # è¾“å‡ºç»“æœæ±‡æ€»
        if quality_issues:
            for issue in quality_issues:
                self.issues['ai_quality'].append(issue)
        else:
            print("  âœ“ AI åˆ†æè´¨é‡åˆæ ¼")
        print()
        
        conn.close()
    
    def print_short_titles(self, conn, short_title_vendors):
        """æ‰“å°è¿‡çŸ­æ ‡é¢˜è¯¦æƒ…"""
        print("ğŸ“ 8.1 çŸ­æ ‡é¢˜è®°å½•ï¼ˆä»…ä¿¡æ¯ï¼‰")
        print("-" * 40)
        
        # å…ˆæ‰“å°æ±‡æ€»
        for vendor, count in short_title_vendors:
            print(f"  {vendor}: {count}æ¡")
        
        cursor = conn.cursor()
        cursor.execute('''
            SELECT vendor, title, product_name, publish_date 
            FROM updates 
            WHERE LENGTH(title) < 2 
            ORDER BY vendor, publish_date
        ''')
        rows = cursor.fetchall()
        
        current_vendor = None
        for vendor, title, product, date in rows:
            if vendor != current_vendor:
                print(f"\n  === {vendor.upper()} ===")
                current_vendor = vendor
            print(f"    [{date}] \"{title}\" - {product}")
        print()
    
    def print_issues_summary(self):
        """è¾“å‡ºé—®é¢˜æ±‡æ€»"""
        print("=" * 60)
        print("ğŸ“ é—®é¢˜æ±‡æ€»")
        print("=" * 60)
        
        total_issues = sum(len(v) for v in self.issues.values())
        
        if total_issues == 0:
            print("âœ… æ­å–œï¼æœªå‘ç°ä»»ä½•æ•°æ®é—®é¢˜ã€‚")
        else:
            print(f"âš ï¸ å…±å‘ç° {total_issues} ä¸ªé—®é¢˜:")
            print()
            
            issue_types = {
                'missing_vendor': 'ç¼ºå¤±å‚å•†æ•°æ®',
                'low_completeness': 'å­—æ®µå®Œæ•´åº¦ä½',
                'empty_required': 'å¿…å¡«å­—æ®µä¸ºç©º',
                'invalid_date': 'æ—¥æœŸæ ¼å¼é”™è¯¯',
                'invalid_url': 'URLæ ¼å¼é”™è¯¯',
                'duplicates': 'é‡å¤æ•°æ®',
                'anomalies': 'æ•°æ®å¼‚å¸¸',
                'ai_quality': 'AIåˆ†æè´¨é‡é—®é¢˜'
            }
            
            for key, label in issue_types.items():
                if self.issues[key]:
                    print(f"  [{label}]")
                    for issue in self.issues[key]:
                        print(f"    - {issue}")
                    print()
    
    def list_empty_subcategory(self) -> list:
        """åˆ—å‡ºæ‰€æœ‰å·²åˆ†æä½† subcategory ä¸ºç©ºçš„è®°å½•"""
        print("=" * 60)
        print("ğŸ“Š å·²åˆ†æä½† subcategory ä¸ºç©ºçš„è®°å½•")
        print("=" * 60)
        
        conn = self.connect()
        cursor = conn.cursor()
        
        # æŸ¥è¯¢å·²åˆ†æï¼ˆtitle_translated ä¸ä¸ºç©ºï¼‰ä½† subcategory ä¸ºç©ºçš„è®°å½•
        cursor.execute("""
            SELECT update_id, vendor, source_channel, title, title_translated, publish_date, source_url
            FROM updates 
            WHERE title_translated IS NOT NULL AND title_translated != ''
            AND (product_subcategory IS NULL OR product_subcategory = '')
            ORDER BY vendor, publish_date DESC
        """)
        
        records = cursor.fetchall()
        conn.close()
        
        if not records:
            print("âœ… æ²¡æœ‰å·²åˆ†æä½† subcategory ä¸ºç©ºçš„è®°å½•")
            return []
        
        # æŒ‰å‚å•†åˆ†ç»„ç»Ÿè®¡
        vendor_stats = defaultdict(int)
        for record in records:
            vendor_stats[record[1]] += 1
        
        print(f"\nå…± {len(records)} æ¡è®°å½•:")
        for vendor, count in sorted(vendor_stats.items()):
            print(f"  {vendor}: {count} æ¡")
        print()
        
        # æ˜¾ç¤ºè¯¦ç»†åˆ—è¡¨ï¼ˆä½¿ç”¨ä¸­æ–‡ç¿»è¯‘æ ‡é¢˜ï¼‰
        print("-" * 60)
        table_data = []
        for update_id, vendor, channel, title, title_translated, date, url in records:
            # ä¼˜å…ˆæ˜¾ç¤ºä¸­æ–‡ç¿»è¯‘æ ‡é¢˜
            display_title = title_translated if title_translated else title
            table_data.append([vendor, date, display_title[:50], update_id[:20]])
        
        print(tabulate(table_data, headers=['å‚å•†', 'æ—¥æœŸ', 'æ ‡é¢˜', 'ID'], tablefmt='simple'))
        print()
        
        return [r[0] for r in records]  # è¿”å› update_id åˆ—è¡¨
    
    def delete_empty_subcategory(self, update_ids: list, confirmed: bool = False) -> int:
        """åˆ é™¤æŒ‡å®šçš„è®°å½•"""
        if not update_ids:
            print("æ²¡æœ‰éœ€è¦åˆ é™¤çš„è®°å½•")
            return 0
        
        if not confirmed:
            print(f"\nâš ï¸  å³å°†åˆ é™¤ {len(update_ids)} æ¡è®°å½•")
            confirm = input("ç¡®è®¤åˆ é™¤ï¼Ÿ(yes/no): ").strip().lower()
            if confirm != 'yes':
                print("å·²å–æ¶ˆåˆ é™¤")
                return 0
        
        conn = self.connect()
        cursor = conn.cursor()
        
        # æ‰¹é‡åˆ é™¤
        placeholders = ','.join(['?' for _ in update_ids])
        cursor.execute(f"DELETE FROM updates WHERE update_id IN ({placeholders})", update_ids)
        
        deleted_count = cursor.rowcount
        conn.commit()
        conn.close()
        
        print(f"\nâœ… å·²åˆ é™¤ {deleted_count} æ¡è®°å½•")
        return deleted_count


class QualityIssueChecker:
    """è´¨é‡é—®é¢˜æ£€æŸ¥å™¨ - ä½¿ç”¨ quality_issues è¡¨"""
    
    def __init__(self):
        self.data_layer = UpdateDataLayer()
    
    def list_issues(
        self,
        issue_type: str = None,
        vendor: str = None,
        show_deleted: bool = False
    ) -> None:
        """åˆ—å‡ºè´¨é‡é—®é¢˜"""
        print("=" * 60)
        if show_deleted:
            print("ğŸ“‹ å·²åˆ é™¤è®°å½•å®¡è®¡æ—¥å¿—")
        else:
            print("ğŸ“‹ å¾…å¤„ç†çš„è´¨é‡é—®é¢˜")
        print("=" * 60)
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = self.data_layer.get_issue_statistics()
        
        print(f"\næ€»è§ˆ:")
        print(f"  å¾…å¤„ç†: {stats['total_open']} æ¡")
        print(f"  å·²è§£å†³: {stats['total_resolved']} æ¡")
        print(f"  å·²å¿½ç•¥: {stats['total_ignored']} æ¡")
        
        if stats['by_type']:
            print(f"\næŒ‰ç±»å‹ç»Ÿè®¡ (å¾…å¤„ç†):")
            for t, count in stats['by_type'].items():
                print(f"  - {t}: {count}")
        
        if stats['by_vendor']:
            print(f"\næŒ‰å‚å•†ç»Ÿè®¡ (å¾…å¤„ç†):")
            for v, count in stats['by_vendor'].items():
                print(f"  - {v}: {count}")
        
        # è·å–è¯¦ç»†åˆ—è¡¨
        if show_deleted:
            issues = self.data_layer._quality.get_deleted_issues(
                issue_type=issue_type,
                vendor=vendor,
                limit=100
            )
        else:
            issues = self.data_layer.get_open_issues(
                issue_type=issue_type,
                vendor=vendor,
                limit=100
            )
        
        if not issues:
            print(f"\nâœ… æ— {'å·²åˆ é™¤' if show_deleted else 'å¾…å¤„ç†'}è®°å½•")
            return
        
        print(f"\n" + "-" * 60)
        print(f"è¯¦ç»†åˆ—è¡¨ (æœ€å¤šæ˜¾ç¤º 100 æ¡):")
        print("-" * 60)
        
        table_data = []
        for issue in issues:
            title = issue.get('title', '')[:40]
            table_data.append([
                issue.get('id'),
                issue.get('vendor', ''),
                issue.get('issue_type', ''),
                title,
                issue.get('detected_at', '')[:10]
            ])
        
        print(tabulate(
            table_data, 
            headers=['ID', 'å‚å•†', 'é—®é¢˜ç±»å‹', 'æ ‡é¢˜', 'æ£€æµ‹æ—¶é—´'], 
            tablefmt='simple'
        ))
        print()
    
    def resolve_issue(self, issue_id: int, action: str, confirmed: bool = False) -> bool:
        """
        è§£å†³è´¨é‡é—®é¢˜
        
        Args:
            issue_id: é—®é¢˜ ID
            action: åŠ¨ä½œ (delete/ignore)
            confirmed: æ˜¯å¦å·²ç¡®è®¤
        """
        # è·å–é—®é¢˜è¯¦æƒ…
        issue = self.data_layer._quality.get_issue_by_id(issue_id)
        if not issue:
            print(f"âŒ é—®é¢˜ ID {issue_id} ä¸å­˜åœ¨")
            return False
        
        if issue['status'] != 'open':
            print(f"âš ï¸  é—®é¢˜ ID {issue_id} çŠ¶æ€ä¸º {issue['status']}ï¼Œæ— éœ€å¤„ç†")
            return False
        
        print(f"\né—®é¢˜è¯¦æƒ…:")
        print(f"  ID: {issue['id']}")
        print(f"  ç±»å‹: {issue['issue_type']}")
        print(f"  å‚å•†: {issue['vendor']}")
        print(f"  æ ‡é¢˜: {issue['title'][:60]}")
        print(f"  é“¾æ¥: {issue['source_url']}")
        print(f"  æ£€æµ‹æ—¶é—´: {issue['detected_at']}")
        
        if action == 'delete':
            if not confirmed:
                confirm = input("\nç¡®è®¤åˆ é™¤å¯¹åº”çš„æ›´æ–°è®°å½•ï¼Ÿ(yes/no): ").strip().lower()
                if confirm != 'yes':
                    print("å·²å–æ¶ˆ")
                    return False
            
            # åˆ é™¤æ›´æ–°è®°å½•
            update_id = issue['update_id']
            success = self.data_layer.delete_update(update_id)
            if success:
                self.data_layer._quality.resolve_issue(issue_id, 'deleted')
                print(f"\nâœ… å·²åˆ é™¤æ›´æ–°è®°å½• {update_id}ï¼Œé—®é¢˜å·²è§£å†³")
                return True
            else:
                print(f"\nâŒ åˆ é™¤æ›´æ–°è®°å½•å¤±è´¥ï¼ˆå¯èƒ½å·²è¢«åˆ é™¤ï¼‰")
                self.data_layer._quality.resolve_issue(issue_id, 'deleted')
                return True
        
        elif action == 'ignore':
            self.data_layer._quality.ignore_issue(issue_id)
            print(f"\nâœ… é—®é¢˜ ID {issue_id} å·²æ ‡è®°ä¸ºå¿½ç•¥")
            return True
        
        else:
            print(f"âŒ æœªçŸ¥åŠ¨ä½œ: {action}")
            return False


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ•°æ®è´¨é‡æ£€æŸ¥å·¥å…·')
    parser.add_argument('--clean-empty', action='store_true', 
                        help='åˆ—å‡ºå¹¶åˆ é™¤å·²åˆ†æä½† subcategory ä¸ºç©ºçš„è®°å½•')
    parser.add_argument('--list-empty', action='store_true',
                        help='ä»…åˆ—å‡ºå·²åˆ†æä½† subcategory ä¸ºç©ºçš„è®°å½•ï¼ˆä¸åˆ é™¤ï¼‰')
    parser.add_argument('--issues', action='store_true',
                        help='æŸ¥çœ‹å¾…å¤„ç†çš„è´¨é‡é—®é¢˜ï¼ˆä½¿ç”¨ quality_issues è¡¨ï¼‰')
    parser.add_argument('--deleted', action='store_true',
                        help='æŸ¥çœ‹å·²åˆ é™¤è®°å½•çš„å®¡è®¡æ—¥å¿—')
    parser.add_argument('--type', type=str, default=None,
                        help='æŒ‰é—®é¢˜ç±»å‹è¿‡æ»¤ (empty_subcategory/not_network_related/analysis_failed)')
    parser.add_argument('--vendor', type=str, default=None,
                        help='æŒ‰å‚å•†è¿‡æ»¤')
    parser.add_argument('--resolve', type=int, default=None,
                        help='è§£å†³æŒ‡å®š ID çš„é—®é¢˜')
    parser.add_argument('--delete', action='store_true',
                        help='ä¸ --resolve é…åˆä½¿ç”¨ï¼Œåˆ é™¤å¯¹åº”è®°å½•')
    parser.add_argument('--ignore', action='store_true',
                        help='ä¸ --resolve é…åˆä½¿ç”¨ï¼Œå¿½ç•¥é—®é¢˜')
    parser.add_argument('-y', '--yes', action='store_true',
                        help='è·³è¿‡ç¡®è®¤æç¤ºï¼Œç›´æ¥æ‰§è¡Œ')
    
    args = parser.parse_args()
    
    # è´¨é‡é—®é¢˜ç›¸å…³å‘½ä»¤
    if args.issues or args.deleted:
        quality_checker = QualityIssueChecker()
        quality_checker.list_issues(
            issue_type=args.type,
            vendor=args.vendor,
            show_deleted=args.deleted
        )
        return
    
    if args.resolve:
        quality_checker = QualityIssueChecker()
        if args.delete:
            quality_checker.resolve_issue(args.resolve, 'delete', confirmed=args.yes)
        elif args.ignore:
            quality_checker.resolve_issue(args.resolve, 'ignore', confirmed=args.yes)
        else:
            print("è¯·æŒ‡å®š --delete æˆ– --ignore")
        return
    
    # åŸæœ‰åŠŸèƒ½
    checker = DataChecker(DB_PATH)
    
    if args.list_empty:
        # ä»…åˆ—å‡ºï¼Œä¸åˆ é™¤
        checker.list_empty_subcategory()
    elif args.clean_empty:
        # åˆ—å‡ºå¹¶åˆ é™¤
        update_ids = checker.list_empty_subcategory()
        if update_ids:
            checker.delete_empty_subcategory(update_ids, confirmed=args.yes)
    else:
        # é»˜è®¤è¿è¡Œæ‰€æœ‰æ£€æŸ¥
        checker.run_all_checks()


if __name__ == '__main__':
    main()
