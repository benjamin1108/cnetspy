#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ•°æ®å­—æ®µå…¨é¢æ’æŸ¥è„šæœ¬

æ£€æŸ¥æ‰€æœ‰å‚å•†çš„æ‰€æœ‰å­—æ®µæ•°æ®å®Œæ•´æ€§å’Œæœ‰æ•ˆæ€§
"""

import os
import sys
import re
import sqlite3
from datetime import datetime
from collections import defaultdict
from tabulate import tabulate

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = os.path.abspath(os.path.dirname(os.path.dirname(__file__)))
sys.path.insert(0, PROJECT_ROOT)

# æ•°æ®åº“è·¯å¾„
DB_PATH = os.path.join(PROJECT_ROOT, 'data', 'sqlite', 'updates.db')

# æ‰€æœ‰å‚å•†
VENDORS = ['aws', 'azure', 'gcp', 'huawei', 'tencentcloud', 'volcengine']

# å¿…å¡«å­—æ®µ
REQUIRED_FIELDS = ['update_id', 'vendor', 'source_channel', 'source_url', 'title', 'publish_date']

# æ‰€æœ‰å­—æ®µ
ALL_FIELDS = [
    'update_id', 'vendor', 'source_channel', 'update_type', 'source_url', 'source_identifier',
    'title', 'title_translated', 'description', 'content', 'content_summary',
    'publish_date', 'crawl_time', 'product_name', 'product_category', 'product_subcategory', 'priority', 'tags',
    'raw_filepath', 'analysis_filepath', 'file_hash', 'metadata_json'
]

# æ—¥æœŸæ ¼å¼æ­£åˆ™
DATE_PATTERN = re.compile(r'^\d{4}-\d{2}-\d{2}')
URL_PATTERN = re.compile(r'^https?://')


class DataChecker:
    """æ•°æ®æ£€æŸ¥å™¨"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.issues = defaultdict(list)
        self.stats = {}
    
    def connect(self):
        """è¿æ¥æ•°æ®åº“"""
        if not os.path.exists(self.db_path):
            print(f"âŒ æ•°æ®åº“ä¸å­˜åœ¨: {self.db_path}")
            sys.exit(1)
        return sqlite3.connect(self.db_path)
    
    def run_all_checks(self):
        """è¿è¡Œæ‰€æœ‰æ£€æŸ¥"""
        print("=" * 60)
        print("ğŸ“Š æ•°æ®å­—æ®µå…¨é¢æ’æŸ¥æŠ¥å‘Š")
        print("=" * 60)
        print(f"æ•°æ®åº“: {self.db_path}")
        print(f"æ£€æŸ¥æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print()
        
        # 1. åŸºç¡€ç»Ÿè®¡
        self.check_basic_stats()
        
        # 2. å„å‚å•†ç»Ÿè®¡
        self.check_vendor_stats()
        
        # 3. å­—æ®µå®Œæ•´åº¦
        self.check_field_completeness()
        
        # 4. å¿…å¡«å­—æ®µæ£€æŸ¥
        self.check_required_fields()
        
        # 5. æ—¥æœŸæ ¼å¼æ£€æŸ¥
        self.check_date_format()
        
        # 6. URLæ ¼å¼æ£€æŸ¥
        self.check_url_format()
        
        # 7. é‡å¤æ•°æ®æ£€æŸ¥
        self.check_duplicates()
        
        # 8. å¼‚å¸¸å€¼æ£€æŸ¥
        self.check_anomalies()
        
        # 9. AI åˆ†æè´¨é‡æ ¡éªŒ
        self.check_ai_quality()
        
        # 10. è¾“å‡ºé—®é¢˜æ±‡æ€»
        self.print_issues_summary()
    
    def check_basic_stats(self):
        """åŸºç¡€ç»Ÿè®¡"""
        print("ğŸ“ˆ 1. åŸºç¡€ç»Ÿè®¡")
        print("-" * 40)
        
        conn = self.connect()
        cursor = conn.cursor()
        
        cursor.execute("SELECT COUNT(*) FROM updates")
        total = cursor.fetchone()[0]
        
        cursor.execute("SELECT MIN(publish_date), MAX(publish_date) FROM updates WHERE publish_date IS NOT NULL AND publish_date != ''")
        date_range = cursor.fetchone()
        
        cursor.execute("SELECT MIN(crawl_time), MAX(crawl_time) FROM updates WHERE crawl_time IS NOT NULL")
        crawl_range = cursor.fetchone()
        
        # æ•°æ®åº“æ–‡ä»¶å¤§å°
        db_size = os.path.getsize(self.db_path) / 1024 / 1024
        
        print(f"  æ€»è®°å½•æ•°: {total}")
        print(f"  å‘å¸ƒæ—¥æœŸèŒƒå›´: {date_range[0]} ~ {date_range[1]}")
        print(f"  çˆ¬å–æ—¶é—´èŒƒå›´: {crawl_range[0][:10] if crawl_range[0] else 'N/A'} ~ {crawl_range[1][:10] if crawl_range[1] else 'N/A'}")
        print(f"  æ•°æ®åº“å¤§å°: {db_size:.2f} MB")
        print()
        
        conn.close()
    
    def check_vendor_stats(self):
        """å„å‚å•†ç»Ÿè®¡"""
        print("ğŸ¢ 2. å„å‚å•†æ•°æ®ç»Ÿè®¡")
        print("-" * 40)
        
        conn = self.connect()
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT vendor, source_channel, COUNT(*) as count 
            FROM updates 
            GROUP BY vendor, source_channel 
            ORDER BY vendor, source_channel
        """)
        
        vendor_data = defaultdict(dict)
        for row in cursor.fetchall():
            vendor, channel, count = row
            vendor_data[vendor][channel] = count
        
        # æ„å»ºè¡¨æ ¼
        table_data = []
        for vendor in VENDORS:
            if vendor in vendor_data:
                channels = vendor_data[vendor]
                total = sum(channels.values())
                channel_str = ', '.join([f"{k}:{v}" for k, v in channels.items()])
                table_data.append([vendor, total, channel_str])
            else:
                table_data.append([vendor, 0, "æ— æ•°æ®"])
                self.issues['missing_vendor'].append(vendor)
        
        print(tabulate(table_data, headers=['å‚å•†', 'æ€»æ•°', 'æ¸ é“åˆ†å¸ƒ'], tablefmt='simple'))
        print()
        
        conn.close()
    
    def check_field_completeness(self):
        """å­—æ®µå®Œæ•´åº¦æ£€æŸ¥"""
        print("ğŸ“‹ 3. å­—æ®µå®Œæ•´åº¦")
        print("-" * 40)
        
        conn = self.connect()
        cursor = conn.cursor()
        
        cursor.execute("SELECT COUNT(*) FROM updates")
        total = cursor.fetchone()[0]
        
        if total == 0:
            print("  æ— æ•°æ®")
            conn.close()
            return
        
        table_data = []
        for field in ALL_FIELDS:
            cursor.execute(f"""
                SELECT COUNT(*) FROM updates 
                WHERE {field} IS NOT NULL AND {field} != ''
            """)
            filled = cursor.fetchone()[0]
            rate = (filled / total) * 100
            status = "âœ“" if rate > 90 else ("âš " if rate > 50 else "âœ—")
            table_data.append([field, filled, f"{rate:.1f}%", status])
            
            if rate < 50 and field in REQUIRED_FIELDS:
                self.issues['low_completeness'].append(f"{field}: {rate:.1f}%")
        
        print(tabulate(table_data, headers=['å­—æ®µ', 'å·²å¡«å……', 'å®Œæ•´ç‡', 'çŠ¶æ€'], tablefmt='simple'))
        print()
        
        conn.close()
    
    def check_required_fields(self):
        """å¿…å¡«å­—æ®µæ£€æŸ¥"""
        print("âš ï¸  4. å¿…å¡«å­—æ®µç©ºå€¼æ£€æŸ¥")
        print("-" * 40)
        
        conn = self.connect()
        cursor = conn.cursor()
        
        has_issue = False
        for field in REQUIRED_FIELDS:
            cursor.execute(f"""
                SELECT vendor, COUNT(*) as count FROM updates 
                WHERE {field} IS NULL OR {field} = ''
                GROUP BY vendor
            """)
            results = cursor.fetchall()
            
            if results:
                has_issue = True
                for vendor, count in results:
                    print(f"  âŒ {vendor}: {field} å­—æ®µä¸ºç©º ({count} æ¡)")
                    self.issues['empty_required'].append(f"{vendor}.{field}: {count}æ¡")
        
        if not has_issue:
            print("  âœ“ æ‰€æœ‰å¿…å¡«å­—æ®µå®Œæ•´")
        print()
        
        conn.close()
    
    def check_date_format(self):
        """æ—¥æœŸæ ¼å¼æ£€æŸ¥"""
        print("ğŸ“… 5. æ—¥æœŸæ ¼å¼æ£€æŸ¥")
        print("-" * 40)
        
        conn = self.connect()
        cursor = conn.cursor()
        
        # æ£€æŸ¥ publish_date
        cursor.execute("""
            SELECT vendor, publish_date, COUNT(*) as count FROM updates 
            WHERE publish_date IS NOT NULL AND publish_date != ''
            GROUP BY vendor, publish_date
        """)
        
        invalid_dates = defaultdict(list)
        for vendor, date_str, count in cursor.fetchall():
            if not DATE_PATTERN.match(str(date_str)):
                invalid_dates[vendor].append((date_str, count))
        
        if invalid_dates:
            for vendor, dates in invalid_dates.items():
                for date_str, count in dates[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                    print(f"  âŒ {vendor}: æ— æ•ˆæ—¥æœŸæ ¼å¼ '{date_str}' ({count}æ¡)")
                    self.issues['invalid_date'].append(f"{vendor}: {date_str}")
                if len(dates) > 3:
                    print(f"      ... è¿˜æœ‰ {len(dates) - 3} ç§æ ¼å¼é—®é¢˜")
        else:
            print("  âœ“ æ‰€æœ‰æ—¥æœŸæ ¼å¼æ­£ç¡®")
        print()
        
        conn.close()
    
    def check_url_format(self):
        """URLæ ¼å¼æ£€æŸ¥"""
        print("ğŸ”— 6. URLæ ¼å¼æ£€æŸ¥")
        print("-" * 40)
        
        conn = self.connect()
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT vendor, source_url FROM updates 
            WHERE source_url IS NOT NULL AND source_url != ''
        """)
        
        invalid_urls = defaultdict(int)
        for vendor, url in cursor.fetchall():
            if not URL_PATTERN.match(str(url)):
                invalid_urls[vendor] += 1
        
        if invalid_urls:
            for vendor, count in invalid_urls.items():
                print(f"  âŒ {vendor}: {count} æ¡æ— æ•ˆURL")
                self.issues['invalid_url'].append(f"{vendor}: {count}æ¡")
        else:
            print("  âœ“ æ‰€æœ‰URLæ ¼å¼æ­£ç¡®")
        print()
        
        conn.close()
    
    def check_duplicates(self):
        """é‡å¤æ•°æ®æ£€æŸ¥"""
        print("ğŸ”„ 7. é‡å¤æ•°æ®æ£€æŸ¥")
        print("-" * 40)
        
        conn = self.connect()
        cursor = conn.cursor()
        
        # æ£€æŸ¥ source_url + source_identifier é‡å¤
        cursor.execute("""
            SELECT vendor, source_url, source_identifier, COUNT(*) as count 
            FROM updates 
            GROUP BY source_url, source_identifier 
            HAVING count > 1
        """)
        
        duplicates = cursor.fetchall()
        if duplicates:
            dup_by_vendor = defaultdict(int)
            for vendor, url, identifier, count in duplicates:
                dup_by_vendor[vendor] += count - 1
            
            for vendor, count in dup_by_vendor.items():
                print(f"  âš ï¸ {vendor}: {count} æ¡é‡å¤è®°å½•")
                self.issues['duplicates'].append(f"{vendor}: {count}æ¡")
        else:
            print("  âœ“ æ— é‡å¤æ•°æ®")
        print()
        
        conn.close()
    
    def check_anomalies(self):
        """å¼‚å¸¸å€¼æ£€æŸ¥"""
        print("ğŸ” 8. å¼‚å¸¸å€¼æ£€æŸ¥")
        print("-" * 40)
        
        conn = self.connect()
        cursor = conn.cursor()
        
        anomalies = []
        
        # æ£€æŸ¥æœªæ¥æ—¥æœŸ
        today = datetime.now().strftime('%Y-%m-%d')
        cursor.execute(f"""
            SELECT vendor, COUNT(*) FROM updates 
            WHERE publish_date > '{today}'
            GROUP BY vendor
        """)
        for vendor, count in cursor.fetchall():
            anomalies.append(f"{vendor}: {count}æ¡æœªæ¥æ—¥æœŸ")
            self.issues['anomalies'].append(f"{vendor}: æœªæ¥æ—¥æœŸ{count}æ¡")
        
        # æ£€æŸ¥è¿‡çŸ­æ ‡é¢˜ (å°‘äº5ä¸ªå­—ç¬¦) - ä»…ä¿¡æ¯å±•ç¤ºï¼Œä¸ä½œä¸ºå‘Šè­¦
        cursor.execute("""
            SELECT vendor, COUNT(*) FROM updates 
            WHERE LENGTH(title) < 2
            GROUP BY vendor
        """)
        short_title_vendors = []
        for vendor, count in cursor.fetchall():
            if count > 0:
                short_title_vendors.append((vendor, count))
        
        # æ£€æŸ¥ç©ºå†…å®¹
        cursor.execute("""
            SELECT vendor, COUNT(*) FROM updates 
            WHERE (content IS NULL OR content = '') AND (description IS NULL OR description = '')
            GROUP BY vendor
        """)
        for vendor, count in cursor.fetchall():
            if count > 0:
                anomalies.append(f"{vendor}: {count}æ¡æ— å†…å®¹å’Œæè¿°")
        
        # æ£€æŸ¥æ— æ•ˆçš„ vendor å€¼
        cursor.execute(f"""
            SELECT DISTINCT vendor FROM updates 
            WHERE vendor NOT IN ({','.join(['?' for _ in VENDORS])})
        """, VENDORS)
        invalid_vendors = [row[0] for row in cursor.fetchall()]
        if invalid_vendors:
            anomalies.append(f"æœªçŸ¥å‚å•†: {', '.join(invalid_vendors)}")
            self.issues['anomalies'].append(f"æœªçŸ¥å‚å•†: {invalid_vendors}")
        
        if anomalies:
            for a in anomalies:
                print(f"  âš ï¸ {a}")
        else:
            print("  âœ“ æœªå‘ç°å¼‚å¸¸å€¼")
        print()
        
        # æ‰“å°è¿‡çŸ­æ ‡é¢˜è¯¦æƒ…ï¼ˆä»…ä¿¡æ¯å±•ç¤ºï¼‰
        if short_title_vendors:
            self.print_short_titles(conn, short_title_vendors)
        
        conn.close()
    
    def check_ai_quality(self):
        """
AI åˆ†æè´¨é‡æ ¡éªŒ
        
        æ ¡éªŒè§„åˆ™ï¼š
        1. ç¿»è¯‘æ ‡é¢˜ä¸å«ä¸­æ–‡
        2. æ‘˜è¦ä¸ºç©º
        3. update_type æ— æ•ˆ
        4. å¿…å¡«å­—æ®µç¼ºå¤±
        """
        print("ğŸ¤– 9. AI åˆ†æè´¨é‡æ ¡éªŒ")
        print("-" * 40)
        
        conn = self.connect()
        cursor = conn.cursor()
        
        # ç»Ÿè®¡å·²åˆ†ææ•°æ®
        cursor.execute("""
            SELECT COUNT(*) FROM updates 
            WHERE title_translated IS NOT NULL
        """)
        total_analyzed = cursor.fetchone()[0]
        
        if total_analyzed == 0:
            print("  æ— å·²åˆ†ææ•°æ®")
            print()
            conn.close()
            return
        
        print(f"  å·²åˆ†æè®°å½•æ•°: {total_analyzed}")
        print()
        
        quality_issues = []
        
        # 1. æ£€æŸ¥ç¿»è¯‘æ ‡é¢˜ä¸å«ä¸­æ–‡
        cursor.execute("""
            SELECT vendor, COUNT(*) FROM updates 
            WHERE title_translated IS NOT NULL
            GROUP BY vendor
        """)
        vendor_analyzed = {vendor: count for vendor, count in cursor.fetchall()}
        
        no_chinese_records = []
        for vendor, analyzed_count in vendor_analyzed.items():
            # ä½¿ç”¨ Python æ­£åˆ™æ£€æŸ¥ä¸­æ–‡
            cursor.execute("""
                SELECT update_id, title, title_translated, publish_date, source_url FROM updates 
                WHERE vendor = ? AND title_translated IS NOT NULL
            """, (vendor,))
            
            for update_id, title, title_translated, date, url in cursor.fetchall():
                if not re.search(r'[ä¸€-é¿¿]', title_translated or ''):
                    no_chinese_records.append({
                        'vendor': vendor,
                        'update_id': update_id,
                        'title': title,
                        'title_translated': title_translated,
                        'date': date,
                        'url': url
                    })
        
        if no_chinese_records:
            for record in no_chinese_records:
                quality_issues.append(f"{record['vendor']}: ç¿»è¯‘æ ‡é¢˜ä¸å«ä¸­æ–‡")
                print(f"\n  âŒ {record['vendor']}: ç¿»è¯‘æ ‡é¢˜ä¸å«ä¸­æ–‡")
                print(f"     ID: {record['update_id']}")
                print(f"     æ—¥æœŸ: {record['date']}")
                print(f"     åŸæ ‡é¢˜: {record['title'][:80]}")
                print(f"     ç¿»è¯‘å: {record['title_translated'][:80]}")
                print(f"     URL: {record['url']}")
        
        # 2. æ£€æŸ¥æ‘˜è¦ä¸ºç©º
        cursor.execute("""
            SELECT vendor, update_id, title, publish_date FROM updates 
            WHERE title_translated IS NOT NULL 
            AND (content_summary IS NULL OR content_summary = '')
        """)
        empty_summary_records = cursor.fetchall()
        
        if empty_summary_records:
            for vendor, update_id, title, date in empty_summary_records:
                quality_issues.append(f"{vendor}: æ‘˜è¦ä¸ºç©º")
                print(f"\n  âŒ {vendor}: æ‘˜è¦ä¸ºç©º")
                print(f"     ID: {update_id}")
                print(f"     æ—¥æœŸ: {date}")
                print(f"     æ ‡é¢˜: {title[:80]}")
        
        # 3. æ£€æŸ¥ update_type æ— æ•ˆ
        valid_types = [
            'new_product', 'new_feature', 'enhancement', 'deprecation', 
            'pricing', 'region', 'security', 'fix', 'performance', 
            'compliance', 'integration', 'other'
        ]
        placeholders = ','.join(['?' for _ in valid_types])
        cursor.execute(f"""
            SELECT vendor, update_id, title, update_type, publish_date FROM updates 
            WHERE title_translated IS NOT NULL 
            AND (update_type IS NULL OR update_type = '' OR update_type NOT IN ({placeholders}))
        """, valid_types)
        
        invalid_type_records = cursor.fetchall()
        if invalid_type_records:
            for vendor, update_id, title, update_type, date in invalid_type_records:
                quality_issues.append(f"{vendor}: update_typeæ— æ•ˆ")
                print(f"\n  âŒ {vendor}: update_typeæ— æ•ˆ")
                print(f"     ID: {update_id}")
                print(f"     æ—¥æœŸ: {date}")
                print(f"     æ ‡é¢˜: {title[:80]}")
                print(f"     å½“å‰å€¼: '{update_type}'")
        
        # 4. æ£€æŸ¥å¿…å¡«å­—æ®µç¼ºå¤±ï¼ˆå·²åˆ†æä½†å­—æ®µä¸ºç©ºï¼‰
        ai_required_fields = ['title_translated', 'content_summary', 'update_type']
        for field in ai_required_fields:
            cursor.execute(f"""
                SELECT vendor, COUNT(*) FROM updates 
                WHERE title_translated IS NOT NULL 
                AND ({field} IS NULL OR {field} = '')
                GROUP BY vendor
            """)
            for vendor, count in cursor.fetchall():
                if count > 0 and field != 'title_translated':  # title_translated å·²åœ¨ä¸Šé¢æ£€æŸ¥
                    quality_issues.append(f"{vendor}: {count}æ¡{field}ä¸ºç©º")
        
        # è¾“å‡ºç»“æœæ±‡æ€»
        if quality_issues:
            for issue in quality_issues:
                self.issues['ai_quality'].append(issue)
        else:
            print("  âœ“ AI åˆ†æè´¨é‡åˆæ ¼")
        print()
        
        conn.close()
    
    def print_short_titles(self, conn, short_title_vendors):
        """æ‰“å°è¿‡çŸ­æ ‡é¢˜è¯¦æƒ…"""
        print("ğŸ“ 8.1 çŸ­æ ‡é¢˜è®°å½•ï¼ˆä»…ä¿¡æ¯ï¼‰")
        print("-" * 40)
        
        # å…ˆæ‰“å°æ±‡æ€»
        for vendor, count in short_title_vendors:
            print(f"  {vendor}: {count}æ¡")
        
        cursor = conn.cursor()
        cursor.execute('''
            SELECT vendor, title, product_name, publish_date 
            FROM updates 
            WHERE LENGTH(title) < 2 
            ORDER BY vendor, publish_date
        ''')
        rows = cursor.fetchall()
        
        current_vendor = None
        for vendor, title, product, date in rows:
            if vendor != current_vendor:
                print(f"\n  === {vendor.upper()} ===")
                current_vendor = vendor
            print(f"    [{date}] \"{title}\" - {product}")
        print()
    
    def print_issues_summary(self):
        """è¾“å‡ºé—®é¢˜æ±‡æ€»"""
        print("=" * 60)
        print("ğŸ“ é—®é¢˜æ±‡æ€»")
        print("=" * 60)
        
        total_issues = sum(len(v) for v in self.issues.values())
        
        if total_issues == 0:
            print("âœ… æ­å–œï¼æœªå‘ç°ä»»ä½•æ•°æ®é—®é¢˜ã€‚")
        else:
            print(f"âš ï¸ å…±å‘ç° {total_issues} ä¸ªé—®é¢˜:")
            print()
            
            issue_types = {
                'missing_vendor': 'ç¼ºå¤±å‚å•†æ•°æ®',
                'low_completeness': 'å­—æ®µå®Œæ•´åº¦ä½',
                'empty_required': 'å¿…å¡«å­—æ®µä¸ºç©º',
                'invalid_date': 'æ—¥æœŸæ ¼å¼é”™è¯¯',
                'invalid_url': 'URLæ ¼å¼é”™è¯¯',
                'duplicates': 'é‡å¤æ•°æ®',
                'anomalies': 'æ•°æ®å¼‚å¸¸',
                'ai_quality': 'AIåˆ†æè´¨é‡é—®é¢˜'
            }
            
            for key, label in issue_types.items():
                if self.issues[key]:
                    print(f"  [{label}]")
                    for issue in self.issues[key]:
                        print(f"    - {issue}")
                    print()


def main():
    """ä¸»å‡½æ•°"""
    checker = DataChecker(DB_PATH)
    checker.run_all_checks()


if __name__ == '__main__':
    main()
