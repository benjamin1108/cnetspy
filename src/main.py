#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
äº‘è®¡ç®—ç«äº‰æƒ…æŠ¥çˆ¬è™«ç³»ç»Ÿ - ä¸»å…¥å£
ç²¾ç®€ç‰ˆï¼šä»…ä¿ç•™çˆ¬è™«æ•°æ®é‡‡é›†åŠŸèƒ½
"""

import argparse
import logging
import logging.config
import os
import sys
from typing import Dict, Any, Optional
from tabulate import tabulate

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
base_dir = os.path.abspath(os.path.dirname(os.path.dirname(__file__)))
sys.path.insert(0, base_dir)

from src.crawlers.common.crawler_manager import CrawlerManager
from src.utils.config.config_loader import get_config as load_config

logger = logging.getLogger(__name__)


def get_config(args: argparse.Namespace) -> Dict[str, Any]:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    return load_config(
        base_dir=base_dir,
        config_path=args.config
    )


def setup_logging(config: Dict[str, Any], debug: bool = False) -> None:
    """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
    log_config = config.get('logging')
    
    if not log_config:
        logging.basicConfig(
            level=logging.DEBUG if debug else logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        return
    
    try:
        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        log_filename = log_config.get('handlers', {}).get('file', {}).get('filename')
        if log_filename:
            log_dir = os.path.dirname(log_filename)
            if log_dir and not os.path.exists(log_dir):
                os.makedirs(log_dir, exist_ok=True)
        
        # è°ƒè¯•æ¨¡å¼ä¸‹è®¾ç½®æ§åˆ¶å°ä¸ºDEBUGçº§åˆ«
        if debug and 'console' in log_config.get('handlers', {}):
            log_config['handlers']['console']['level'] = 'DEBUG'
        
        logging.config.dictConfig(log_config)
        logger.debug("æ—¥å¿—ç³»ç»Ÿé…ç½®å®Œæˆ")
        
    except Exception as e:
        logging.basicConfig(level=logging.INFO)
        logger.error(f"æ—¥å¿—é…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")


def parse_args() -> argparse.Namespace:
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="äº‘è®¡ç®—ç«äº‰æƒ…æŠ¥çˆ¬è™«")
    parser.add_argument("--vendor", help="æŒ‡å®šå‚å•†: aws, azure, gcp, huawei, tencentcloud, volcengine")
    parser.add_argument("--source", help="æŒ‡å®šæ•°æ®æº: blog, whatsnew, updatesç­‰")
    parser.add_argument("--limit", type=int, default=0, help="æ¯ä¸ªæºçš„æ–‡ç« æ•°é‡é™åˆ¶")
    parser.add_argument("--config", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--force", action="store_true", help="å¼ºåˆ¶é‡æ–°çˆ¬å–ï¼Œå¿½ç•¥å·²å­˜åœ¨çš„æ•°æ®")
    parser.add_argument("--debug", action="store_true", help="è°ƒè¯•æ¨¡å¼")
    return parser.parse_args()


def run_crawler(args: argparse.Namespace) -> int:
    """
    è¿è¡Œçˆ¬è™«
    
    Returns:
        0: æˆåŠŸ
        1: å¤±è´¥
    """
    config = get_config(args)
    
    # è¿‡æ»¤å‚å•†å’Œæ•°æ®æº
    sources = config.get('sources', {})
    
    if args.vendor:
        # æŒ‡å®šäº†å‚å•†
        if args.vendor not in sources:
            logger.error(f"æœªæ‰¾åˆ°å‚å•†é…ç½®: {args.vendor}")
            return 1
        config['sources'] = {args.vendor: sources[args.vendor]}
        
        # è¿‡æ»¤æ•°æ®æºï¼ˆæ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼‰
        if args.source:
            vendor_sources = config['sources'][args.vendor]
            source_pattern = args.source.lower()
            matching_sources = {
                name: cfg for name, cfg in vendor_sources.items()
                if source_pattern in name.lower()
            }
            if not matching_sources:
                logger.error(f"æœªæ‰¾åˆ°æ•°æ®æºé…ç½®: {args.vendor}/{args.source}")
                return 1
            config['sources'][args.vendor] = matching_sources
            logger.info(f"çˆ¬å–ç›®æ ‡: {args.vendor} çš„ {args.source} æ•°æ®æº (å…± {len(matching_sources)} ä¸ª)")
        else:
            logger.info(f"çˆ¬å–ç›®æ ‡: {args.vendor} (å…¨éƒ¨æ•°æ®æº)")
    elif args.source:
        # ä»…æŒ‡å®šæ•°æ®æºç±»å‹ï¼Œè¿‡æ»¤æ‰€æœ‰å‚å•†ä¸­åŒ¹é…çš„æ•°æ®æº
        filtered_sources = {}
        source_pattern = args.source.lower()
        
        for vendor, vendor_sources in sources.items():
            matching_sources = {}
            for source_name, source_config in vendor_sources.items():
                # åŒ¹é…è§„åˆ™ï¼šsource_name åŒ…å«æŒ‡å®šçš„ç±»å‹ï¼ˆå¦‚ blog åŒ¹é… network-blog, tech-blog ç­‰ï¼‰
                if source_pattern in source_name.lower():
                    matching_sources[source_name] = source_config
            
            if matching_sources:
                filtered_sources[vendor] = matching_sources
        
        if not filtered_sources:
            logger.error(f"æœªæ‰¾åˆ°åŒ¹é…çš„æ•°æ®æº: {args.source}")
            return 1
        
        config['sources'] = filtered_sources
        matched_count = sum(len(v) for v in filtered_sources.values())
        logger.info(f"çˆ¬å–ç›®æ ‡: æ‰€æœ‰å‚å•†çš„ {args.source} æ•°æ®æº (å…± {matched_count} ä¸ª)")
    else:
        logger.info("çˆ¬å–ç›®æ ‡: å…¨éƒ¨å‚å•†")
    
    # è®¾ç½®é™åˆ¶
    if args.limit > 0:
        config.setdefault('crawler', {})['article_limit'] = args.limit
        logger.info(f"æ–‡ç« æ•°é‡é™åˆ¶: {args.limit}")
    
    # å¼ºåˆ¶æ¨¡å¼
    if args.force:
        config.setdefault('crawler', {})['force'] = True
        logger.info("å¼ºåˆ¶æ¨¡å¼: å¿½ç•¥å·²å­˜åœ¨çš„æ•°æ®")
    
    # è¿è¡Œçˆ¬è™«
    crawler_manager = CrawlerManager(config)
    result = crawler_manager.run()
    
    if not result:
        logger.error("çˆ¬è™«ä»»åŠ¡å¤±è´¥")
        return 1
    
    # è¾“å‡ºç»“æœæ‘˜è¦
    total_files = 0
    crawl_data = []  # æ”¶é›†æŠ¥å‘Šæ•°æ®
    
    for vendor, vendor_results in result.items():
        for source_type, files in vendor_results.items():
            count = len(files)
            total_files += count
            if count > 0:
                crawl_data.append([vendor, source_type, count])
    
    # æ ¼å¼åŒ–è¾“å‡ºæŠ¥å‘Š
    print("\n" + "=" * 60)
    print("ğŸ•·ï¸ çˆ¬å–ä»»åŠ¡æŠ¥å‘Š")
    print("=" * 60)
    
    if crawl_data:
        print(tabulate(crawl_data, headers=["å‚å•†", "æ•°æ®æº", "æ–‡ä»¶æ•°"], tablefmt="simple"))
        print("-" * 40)
    
    print(f"æ€»è®¡: {total_files} ä¸ªæ–‡ä»¶")
    print("=" * 60 + "\n")
    
    return 0


def main() -> int:
    """ä¸»å…¥å£"""
    args = parse_args()
    config = get_config(args)
    
    setup_logging(config, debug=args.debug)
    
    if args.debug:
        logger.info("è°ƒè¯•æ¨¡å¼å·²å¯ç”¨")
    
    return run_crawler(args)


if __name__ == "__main__":
    sys.exit(main())
