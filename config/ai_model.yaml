# AI 模型配置文件

# 默认配置（批量分析任务使用）
default:
  # LLM 服务商
  provider: gemini
  
  # 模型名称
  model_name: gemini-3-flash-preview
  
  # API Key 环境变量名称（实际的 API Key 从环境变量读取）
  api_key_env: GEMINI_API_KEY
  
  # 生成参数
  generation:
    # 温度：控制输出的随机性 (0.0-1.0)
    # 较低的值使输出更确定，较高的值使输出更有创造性
    temperature: 0.5
    
    # Top-p：核采样参数 (0.0-1.0)
    # 控制输出的多样性
    top_p: 0.9
    
    # Top-k：候选词数量
    # 限制每步采样的候选词数量
    top_k: 40
    
    # 最大输出令牌数
    max_output_tokens: 65535
  
  # 速率限制
  rate_limit:
    # API 调用间隔（秒）
    interval: 0.5
    
    # 最大重试次数
    max_retries: 5
    
    # 重试退避基数（指数退避）
    retry_backoff_base: 1.0
  
  # 批量分析配置
  batch_processing:
    # 并发线程数
    max_workers: 50
  
  # 字段验证规则
  validation:
    # title_translated 最大长度（字符）
    title_max_length: 50
    
    # content_summary 长度范围（字符）
    summary_min_length: 150
    summary_max_length: 500
    summary_max_items: 5
    
    # tags 数量范围
    tags_min_count: 3
    tags_max_count: 8

# Chatbox 配置（前端 AI 助手使用）
chatbox:
  # 模型名称（可与 default 不同）
  model_name: gemini-3-flash-preview
  
  # API Key 环境变量名称（复用 default 的 key）
  api_key_env: GEMINI_API_KEY
  
  # 生成参数
  generation:
    temperature: 0.7
    max_output_tokens: 4096
